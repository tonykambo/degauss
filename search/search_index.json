{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Degauss \u00b6 A collection of interests and hobbies for the purpose of decluttering the mind and sharing knowledge. \"Degaussing is the process of decreasing or eliminating a remnant magnetic field. It is named after the gauss, a unit of magnetism, which in turn was named after Carl Friedrich Gauss.\" - Wikipedia","title":"Home"},{"location":"#welcome-to-degauss","text":"A collection of interests and hobbies for the purpose of decluttering the mind and sharing knowledge. \"Degaussing is the process of decreasing or eliminating a remnant magnetic field. It is named after the gauss, a unit of magnetism, which in turn was named after Carl Friedrich Gauss.\" - Wikipedia","title":"Welcome to Degauss"},{"location":"electronics/apollodsky/","text":"Building an Apollo DSKY mock device \u00b6 The Apollo Guidance Computer (AGC) Display and Keyboard (DKSY) mock device will only simulate a few key scenarios from Apollo 11 and Apollo 13. The hardware will comprise a 3D printed shell with a built in ESP32 driving the keypad and LEDs. It will be powered by a rechargable LiPo battery.","title":"Apollo DSKY Replica"},{"location":"electronics/apollodsky/#building-an-apollo-dsky-mock-device","text":"The Apollo Guidance Computer (AGC) Display and Keyboard (DKSY) mock device will only simulate a few key scenarios from Apollo 11 and Apollo 13. The hardware will comprise a 3D printed shell with a built in ESP32 driving the keypad and LEDs. It will be powered by a rechargable LiPo battery.","title":"Building an Apollo DSKY mock device"},{"location":"electronics/rocketlaunchcontroller/","text":"Model Rocket Launch Controller \u00b6 Progress 5% My Estes model rocket launch controller is no longer functioning. Time to build my own. The following circuit provides three switches: - Power - switches the power on. - Arm - Readies the circuit for launch. - Launch - ignites the starter. I set up a simple circuit with one push button to test igniting the starter with a single 9V battery.","title":"Rocket Launch Controller"},{"location":"electronics/rocketlaunchcontroller/#model-rocket-launch-controller","text":"Progress 5% My Estes model rocket launch controller is no longer functioning. Time to build my own. The following circuit provides three switches: - Power - switches the power on. - Arm - Readies the circuit for launch. - Launch - ignites the starter. I set up a simple circuit with one push button to test igniting the starter with a single 9V battery.","title":"Model Rocket Launch Controller"},{"location":"gaming/xboxsetup/","text":"Xbox Series S Setup \u00b6 The Xbox Series S is a relatively low cost entry into the Microsoft gaming world for Mac users. There were three games in particular that nudged me over the line to buy an Xbox: Halo Gears 5 MS Flight Simulator Since the Xbox is connected to my monitor (LG 38WN95C-W) it has the additional benefit of rendering Fortnite at 120 fps given the monitor supports 144 Hz. Recoring gameplay on the Xbox is limited compared to the PS5. To allow for long record times an external drive must be connected however the drive must be formatted in NTFS. This is a challenge with a Mac only household. I installed Paragon Software's MS NTFS for Mac and formatted a Sandisk Extreme SSD (1 TB) with NFTS. Unfortunately the Xbox did not recognise the drive. I formatted the drive as exFAT and it did recognise it. I installed Parallels 17 and Windows 10 ARM edition, formatted the drive within Windows as NTFS and that was recongised by the Xbox. Installing Paragon's MS NTFS sofware does require you to enable kernal extensions by booting into Recovery Mode to enable it. This doesn't feel safe so i'll stick with Parallels and Windows to continue copying gameplay footage from the external drive. I've also switched to using the Sandisk Ultra Flair USB 3.0 128 GB thumb drive. This has plenty of storage and sufficient speed for recording gameplay on the Xbox. As macOS supports reading NTFS drives (but does not support writing) I can copy gameplay recordings simply with Finder without needing to launch Windows via Parallels again.","title":"Xbox"},{"location":"gaming/xboxsetup/#xbox-series-s-setup","text":"The Xbox Series S is a relatively low cost entry into the Microsoft gaming world for Mac users. There were three games in particular that nudged me over the line to buy an Xbox: Halo Gears 5 MS Flight Simulator Since the Xbox is connected to my monitor (LG 38WN95C-W) it has the additional benefit of rendering Fortnite at 120 fps given the monitor supports 144 Hz. Recoring gameplay on the Xbox is limited compared to the PS5. To allow for long record times an external drive must be connected however the drive must be formatted in NTFS. This is a challenge with a Mac only household. I installed Paragon Software's MS NTFS for Mac and formatted a Sandisk Extreme SSD (1 TB) with NFTS. Unfortunately the Xbox did not recognise the drive. I formatted the drive as exFAT and it did recognise it. I installed Parallels 17 and Windows 10 ARM edition, formatted the drive within Windows as NTFS and that was recongised by the Xbox. Installing Paragon's MS NTFS sofware does require you to enable kernal extensions by booting into Recovery Mode to enable it. This doesn't feel safe so i'll stick with Parallels and Windows to continue copying gameplay footage from the external drive. I've also switched to using the Sandisk Ultra Flair USB 3.0 128 GB thumb drive. This has plenty of storage and sufficient speed for recording gameplay on the Xbox. As macOS supports reading NTFS drives (but does not support writing) I can copy gameplay recordings simply with Finder without needing to launch Windows via Parallels again.","title":"Xbox Series S Setup"},{"location":"modelrockets/estessaturnv/","text":"Estes Saturn V Model Rocket \u00b6 Coming soon","title":"Estessaturnv"},{"location":"modelrockets/estessaturnv/#estes-saturn-v-model-rocket","text":"Coming soon","title":"Estes Saturn V Model Rocket"},{"location":"retrogaming/arcade/","text":"Arcade Machine \u00b6 Coming soon","title":"Arcade"},{"location":"retrogaming/arcade/#arcade-machine","text":"Coming soon","title":"Arcade Machine"},{"location":"retrogaming/atari2600/","text":"Atari 2600 \u00b6 Coming soon Game Catalogue Centipede Pitfall","title":"Atari2600"},{"location":"retrogaming/atari2600/#atari-2600","text":"Coming soon Game Catalogue Centipede Pitfall","title":"Atari 2600"},{"location":"retrogaming/commodore64/","text":"Commodore 64 Games \u00b6 Afterburner International Karate +","title":"Commodore 64 Games"},{"location":"retrogaming/commodore64/#commodore-64-games","text":"Afterburner International Karate +","title":"Commodore 64 Games"},{"location":"retrogear/commodore64/","text":"","title":"Commodore64"},{"location":"retrogear/macintoshquadra700/","text":"Apple Macintosh Quadra 700 \u00b6 Also known as the computer from the Jurassic Park movie the Macintosh Quadra 700 comprises a 32-bit 68040 CPU running at 25 MHz. I found one on eBay with the following specifications: 20 MB RAM 250 MB HDD 1.44 Floppy The assembled setup includes the following components: Apple keyboard Apple mouse AAUI adapter D15 Male to Male monitor cable Apple Macintosh AppleColor 13\" High Resolution RGB Display Monitor (M0401z )","title":"Apple Macintosh Quadra 700"},{"location":"retrogear/macintoshquadra700/#apple-macintosh-quadra-700","text":"Also known as the computer from the Jurassic Park movie the Macintosh Quadra 700 comprises a 32-bit 68040 CPU running at 25 MHz. I found one on eBay with the following specifications: 20 MB RAM 250 MB HDD 1.44 Floppy The assembled setup includes the following components: Apple keyboard Apple mouse AAUI adapter D15 Male to Male monitor cable Apple Macintosh AppleColor 13\" High Resolution RGB Display Monitor (M0401z )","title":"Apple Macintosh Quadra 700"},{"location":"retrogear/macintoshse/","text":"","title":"Macintoshse"},{"location":"retrogear/recordplayer/","text":"Record Player \u00b6 Coming soon","title":"Recordplayer"},{"location":"retrogear/recordplayer/#record-player","text":"Coming soon","title":"Record Player"},{"location":"technology/materialisedviews/","text":"Constructing a materialised view in Confluent Cloud (Kafka) using ksqlDB \u00b6 Using Kafka to store a copy of customer data from a CRM system. Cater for new customers added to the system. Cater for customer details being changed. Providing a materialised view where only the latest changes to the customer are retrieved. Set up a Confluent Cloud account with ksqlDB. docker run --rm -it confluentinc/ksqldb-cli:0.23.1 ksql -u <KSQL_USER_ID> -p <KSQL_PASSWORD> \"https://<confluent-cloud-hostname>.aws.confluent.cloud:443\" create stream customers ( id INT KEY , firstname VARCHAR , lastname VARCHAR , email VARCHAR , residency VARCHAR , dateOfBirth TIMESTAMP , sexAtBirth VARCHAR , occupation VARCHAR ) WITH ( KAFKA_TOPIC = 'customers' , value_format = 'JSON' , PARTITIONS = 6 ); Show the stream and topics created: ksql > show streams ; Stream Name | Kafka Topic | Key Format | Value Format | Windowed ------------------------------------------------------------------------------------------------- CUSTOMERS | customers | KAFKA | JSON | false KSQL_PROCESSING_LOG | pksqlc - vn80j - processing - log | KAFKA | JSON | false RIDERLOCATIONS | quickstart - locations | KAFKA | JSON | false STARTENQUIRYREQUESTSTREAM | startEnquiryRequest - topic | KAFKA | JSON | false STARTENQUIRYRESPONSESTREAM | startEnquiryResponse - topic | KAFKA | JSON | false USERS | users | KAFKA | JSON | false ------------------------------------------------------------------------------------------------- ksql > show topics ; Kafka Topic | Partitions | Partition Replicas ---------------------------------------------------------------------- customers | 6 | 3 pksqlc - vn80j - processing - log | 8 | 3 pksqlc - vn80jCURRENTLOCATION | 1 | 3 pksqlc - vn80jRIDERSNEARMOUNTAINVIEW | 1 | 3 quickstart - locations | 1 | 3 startEnquiryRequest - topic | 1 | 3 startEnquiryResponse - topic | 1 | 3 testtopic | 6 | 3 users | 1 | 3 ---------------------------------------------------------------------- Adding records into the stream: insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 1 , 'John' , 'Smith' , 'john@nowhere.com' , 'NZCitizen' , '1955-11-05T06:00:00' , 'Male' , 'SelfEmployed' ); insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 2 , 'Peter' , 'Jones' , 'peter@thisthat.com' , 'NZCitizen' , '1945-10-06T06:00:00' , 'Male' , 'Employed' ); insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 3 , 'Felicity' , 'Hoffman' , 'felicity@thehoff.org' , 'NZCitizen' , '1965-12-24T06:00:00' , 'Female' , 'Student' );","title":"Constructing a materialised view in Confluent Cloud (Kafka) using ksqlDB"},{"location":"technology/materialisedviews/#constructing-a-materialised-view-in-confluent-cloud-kafka-using-ksqldb","text":"Using Kafka to store a copy of customer data from a CRM system. Cater for new customers added to the system. Cater for customer details being changed. Providing a materialised view where only the latest changes to the customer are retrieved. Set up a Confluent Cloud account with ksqlDB. docker run --rm -it confluentinc/ksqldb-cli:0.23.1 ksql -u <KSQL_USER_ID> -p <KSQL_PASSWORD> \"https://<confluent-cloud-hostname>.aws.confluent.cloud:443\" create stream customers ( id INT KEY , firstname VARCHAR , lastname VARCHAR , email VARCHAR , residency VARCHAR , dateOfBirth TIMESTAMP , sexAtBirth VARCHAR , occupation VARCHAR ) WITH ( KAFKA_TOPIC = 'customers' , value_format = 'JSON' , PARTITIONS = 6 ); Show the stream and topics created: ksql > show streams ; Stream Name | Kafka Topic | Key Format | Value Format | Windowed ------------------------------------------------------------------------------------------------- CUSTOMERS | customers | KAFKA | JSON | false KSQL_PROCESSING_LOG | pksqlc - vn80j - processing - log | KAFKA | JSON | false RIDERLOCATIONS | quickstart - locations | KAFKA | JSON | false STARTENQUIRYREQUESTSTREAM | startEnquiryRequest - topic | KAFKA | JSON | false STARTENQUIRYRESPONSESTREAM | startEnquiryResponse - topic | KAFKA | JSON | false USERS | users | KAFKA | JSON | false ------------------------------------------------------------------------------------------------- ksql > show topics ; Kafka Topic | Partitions | Partition Replicas ---------------------------------------------------------------------- customers | 6 | 3 pksqlc - vn80j - processing - log | 8 | 3 pksqlc - vn80jCURRENTLOCATION | 1 | 3 pksqlc - vn80jRIDERSNEARMOUNTAINVIEW | 1 | 3 quickstart - locations | 1 | 3 startEnquiryRequest - topic | 1 | 3 startEnquiryResponse - topic | 1 | 3 testtopic | 6 | 3 users | 1 | 3 ---------------------------------------------------------------------- Adding records into the stream: insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 1 , 'John' , 'Smith' , 'john@nowhere.com' , 'NZCitizen' , '1955-11-05T06:00:00' , 'Male' , 'SelfEmployed' ); insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 2 , 'Peter' , 'Jones' , 'peter@thisthat.com' , 'NZCitizen' , '1945-10-06T06:00:00' , 'Male' , 'Employed' ); insert into customers ( id , firstname , lastname , email , residency , dateofbirth , sexatbirth , occupation ) values ( 3 , 'Felicity' , 'Hoffman' , 'felicity@thehoff.org' , 'NZCitizen' , '1965-12-24T06:00:00' , 'Female' , 'Student' );","title":"Constructing a materialised view in Confluent Cloud (Kafka) using ksqlDB"}]}